{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pSv-B0lhFUV"
      },
      "source": [
        "# Brain Wave Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3RLLBYEjDo_"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/train_data.csv')\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43cq0uIPjP0E"
      },
      "outputs": [],
      "source": [
        "train_data[['label', 'C3_Delta', 'C3_Theta', 'C3_Alpha', 'C3_Beta', 'C3_Gamma', 'C4_Delta', 'C4_Theta', 'C4_Alpha', 'C4_Beta', 'C4_Gamma']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVGhlI-YjDir"
      },
      "outputs": [],
      "source": [
        "X = train_data[['label', 'C3_Delta', 'C3_Theta', 'C3_Alpha', 'C3_Beta', 'C3_Gamma', 'C4_Delta', 'C4_Theta', 'C4_Alpha', 'C4_Beta', 'C4_Gamma']]\n",
        "\n",
        "y = train_data[\"label\"]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HiPvYlNiG94"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import lightgbm as lgb\n",
        "import xgbm as xgb\n",
        "import catboost as cb\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objective(trial):\n",
        "    # Define hyperparameter search spaces\n",
        "    xgb_params = {\n",
        "        'max_depth': trial.suggest_int('xgb_max_depth', 2, 10),\n",
        "        'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 1000),\n",
        "        'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3),\n",
        "    }\n",
        "    nn_params = {\n",
        "        'lr': trial.suggest_float('nn_lr', 1e-5, 1e-2, log=True),\n",
        "        'wd': trial.suggest_float('nn_wd', 1e-5, 1e-2, log=True),\n",
        "    }\n",
        "    lgb_params = {\n",
        "        'max_depth': trial.suggest_int('lgb_max_depth', 2, 10),\n",
        "        'num_leaves': trial.suggest_int('lgb_num_leaves', 10, 100),\n",
        "        'learning_rate': trial.suggest_float('lgb_learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('lgb_n_estimators', 100, 1000),\n",
        "    }\n",
        "    cb_params = {\n",
        "        'depth': trial.suggest_int('cb_depth', 2, 10),\n",
        "        'iterations': trial.suggest_int('cb_iterations', 100, 1000),\n",
        "        'learning_rate': trial.suggest_float('cb_learning_rate', 0.01, 0.3),\n",
        "    }\n",
        "    rf_params = {\n",
        "        'n_estimators': trial.suggest_int('rf_n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('rf_max_depth', 2, 10),\n",
        "    }\n",
        "\n",
        "    # Create base models\n",
        "    xgb_model = xgb.XGBClassifier(**xgb_params, random_state=42)\n",
        "    nn_model = NeuralNetFastAI(**nn_params, random_state=42)\n",
        "    lgb_model = lgb.LGBMClassifier(**lgb_params, random_state=42)\n",
        "    cb_model = cb.CatBoostClassifier(**cb_params, random_state=42)\n",
        "    rf_model = RandomForestClassifier(**rf_params, random_state=42)\n",
        "\n",
        "    # Create voting classifier with given weights\n",
        "    voting_clf = VotingClassifier(estimators=[\n",
        "        ('XGBoost', xgb_model, 0.5),\n",
        "        ('NeuralNetFastAI', nn_model, 0.2),\n",
        "        ('LightGBM', lgb_model, 0.1),\n",
        "        ('RandomForestEntr', rf_model, 0.1),\n",
        "        ('CatBoost', cb_model, 0.1)\n",
        "    ], voting='soft')\n",
        "\n",
        "    # Fit and evaluate\n",
        "    voting_clf.fit(X_train, y_train)\n",
        "    y_pred = voting_clf.predict(X_val)\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    return f1\n",
        "\n",
        "# Assuming you have your data loaded and split into X_train, y_train, X_val, y_val\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\", study_name=\"voting-ensemble\", storage=\"sqlite:///voting.db\", load_if_exists=True)\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_params = study.best_trial.params\n",
        "\n",
        "print('Best parameters:', study.best_params)\n",
        "print('Best score:', study.best_value)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    **{k[4:]: v for k, v in best_params.items() if k.startswith('xgb_')})\n",
        "\n",
        "nn_model = NeuralNetFastAI(\n",
        "    **{k[3:]: v for k, v in best_params.items() if k.startswith('nn_')})\n",
        "\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    **{k[4:]: v for k, v in best_params.items() if k.startswith('lgb_')})\n",
        "\n",
        "cb_model = cb.CatBoostClassifier(\n",
        "    **{k[3:]: v for k, v in best_params.items() if k.startswith('cb_')})\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    **{k[3:]: v for k, v in best_params.items() if k.startswith('rf_')})\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('XGBoost', xgb_model, 0.5),\n",
        "    ('NeuralNetFastAI', nn_model, 0.2),\n",
        "    ('LightGBM', lgb_model, 0.1),\n",
        "    ('RandomForestEntr', rf_model, 0.1),\n",
        "    ('CatBoost', cb_model, 0.1)\n",
        "], voting='soft')\n",
        "\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "import joblib\n",
        "\n",
        "joblib.dump(voting_clf, \"voting-ensemble.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDLN89DsibJX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
